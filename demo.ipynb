{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Assisted Data Annotation toolkit\n",
    "In this demo, we show a use case of our ML-assisted data anotation pipeline particularly for the 2D object detection task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Figure. 1 provides an overview of an annotation pipeline which can be supported by the toolkit. The pipeline consists of the following 6 major steps:\n",
    "Unlabelled data (Input): The toolkit allows user to load unlabelled data in supported data formats. \n",
    "\n",
    "- **Selected pre-trained model (input):** The user selects a pre-trained model from an existing model pool or insert their pre-trained propriety model.  \n",
    "\n",
    "- **Select a subset of data:** A subset of dataset is selected for the current round of labelling. The order of subset selection can be defined either randomly, by user’s preference (e.g., to prioritise images with new labels) or by active-learning prioritisation.  \n",
    "\n",
    "- **Run the ML model to label the data:** The ML model processes the subset of data and produces pre-annotation.  \n",
    "\n",
    "- **Create/Refine/Review labels by user:** The user can manually create, refine, or review the produced labels resulting in the final labels for the current subset.  \n",
    "\n",
    "- **Evaluate the model:** The ML model performance is evaluated on this subset by comparing the produced labels with the manually refined ones.  \n",
    "\n",
    "- **Check the performance:** The performance score of the model is checked against a threshold. If the score surpasses the threshold, next round of labelling will be repeated from step 1, otherwise, the model is re-trained in the following step.  \n",
    "\n",
    "- **Retrain the model:** The model is re-trained on this subset using the hyper-parameters defined by the user. The next round of labelling will be initiated when the training is finished. \n",
    "\n",
    "- **Labelled data:** The toolkit allows exporting labelled data in supported data formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](assets/pipeline.png)\n",
    "\n",
    "*Figure1. An overview of the ML-assisted data annotation pipeline*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import non_max_suppression, bbox_iou_numpy, compute_ap, Visualizer, weights_init_normal, draw_bbox, convert_target_to_detection\n",
    "from utils.datasets import Image2DAnnotationDataset\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import pickle\n",
    "from random import sample\n",
    "import os\n",
    "import argparse\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from models import Darknet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset selection\n",
    "\n",
    "The next code snippet defines a function for selecting a subset of data based on a query method, either 'random' or 'confidence-based'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_selection(model, train_dataset, subset_size, query_mode, opt):\n",
    "    model.eval()\n",
    "    selection_size = min(len(train_dataset), subset_size)\n",
    "    if query_mode == 'random':\n",
    "        subset_indices = np.random.choice(np.arange(len(train_dataset)), selection_size, replace=False)\n",
    "        \n",
    "    elif query_mode == 'conf':\n",
    "        sample_scores = np.ones(len(train_dataset), dtype=np.float32)\n",
    "        dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.n_cpu)\n",
    "        output_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (_, imgs, _) in enumerate(tqdm.tqdm(dataloader, desc=\"Selecting the most informative samples\")):\n",
    "                imgs = imgs.to('cuda')\n",
    "                outputs = model(imgs)\n",
    "                outputs = non_max_suppression(outputs, 80, conf_thres=opt.conf_thres, nms_thres=opt.nms_thres)\n",
    "                output_list.extend(outputs)\n",
    "        for i, output in enumerate(output_list):\n",
    "            if  output is not None:\n",
    "                box_scores = output[:, 4].cpu().numpy()\n",
    "                sample_scores[i] = box_scores.mean()\n",
    "        subset_indices = np.argsort(sample_scores)[:selection_size]\n",
    "    labelled_sub_dataset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "    return labelled_sub_dataset, subset_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "The following code snippet defines a function for visualisation of an image and its annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_annotation(model, img_path, img, target, classes_to_labels, opt, labels, img_size=416, resize_tuple=None, show_target=False):\n",
    "    model.eval()\n",
    "    img = img.to('cuda').unsqueeze(axis=0)\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        output = non_max_suppression(output, 80, classes_to_labels, conf_thres=opt.conf_thres, nms_thres=opt.nms_thres)\n",
    "    if show_target:\n",
    "        output_ = convert_target_to_detection(target, img_size)\n",
    "        if output_ is not None:\n",
    "            draw_bbox(img_path, output_, labels, img_size, resize_tuple)\n",
    "    if output[0] is not None:\n",
    "        draw_bbox(img_path, output[0], labels, img_size, resize_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "The next code snippet defines a function for evaluation of model based on mean average precision (mAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, num_classes, opt, best_mAP, classes_to_labels, labels_to_classes, avg_precision, labels, vis, iteration, is_val=True):\n",
    "    model.eval()\n",
    "    all_detections = []\n",
    "    all_annotations = []\n",
    "    for batch_i, (imgs_path, imgs, targets) in enumerate(tqdm.tqdm(data_loader, desc=\"mAP_evaluation\")):\n",
    "\n",
    "        imgs = imgs.to('cuda')\n",
    "        with torch.no_grad():\n",
    "            outputs = model(imgs)\n",
    "            outputs = non_max_suppression(outputs, 80, classes_to_labels, conf_thres=opt.conf_thres, nms_thres=opt.nms_thres)\n",
    "\n",
    "        for output, annotations in zip(outputs, targets):\n",
    "            all_detections.append([np.array([]) for _ in range(num_classes)])\n",
    "            if output is not None:\n",
    "                # Get predicted boxes, confidence scores and labels\n",
    "                pred_boxes = output[:, :5].cpu().numpy()\n",
    "                scores = output[:, 4].cpu().numpy()\n",
    "                pred_labels = output[:, -1].cpu().numpy()\n",
    "\n",
    "                # Order by confidence\n",
    "                sort_i = np.argsort(scores)\n",
    "                pred_labels = pred_labels[sort_i]\n",
    "                pred_boxes = pred_boxes[sort_i]\n",
    "\n",
    "                for label in range(num_classes):\n",
    "                    all_detections[-1][label] = pred_boxes[pred_labels == label]\n",
    "\n",
    "            all_annotations.append([np.array([]) for _ in range(num_classes)])\n",
    "            if any(annotations[:, -1] > 0):\n",
    "\n",
    "                annotation_labels = annotations[annotations[:, -1] > 0, 0].numpy()\n",
    "                _annotation_boxes = annotations[annotations[:, -1] > 0, 1:]\n",
    "\n",
    "                # Reformat to x1, y1, x2, y2 and rescale to image dimensions\n",
    "                annotation_boxes = np.empty_like(_annotation_boxes)\n",
    "                annotation_boxes[:, 0] = _annotation_boxes[:, 0] - _annotation_boxes[:, 2] / 2\n",
    "                annotation_boxes[:, 1] = _annotation_boxes[:, 1] - _annotation_boxes[:, 3] / 2\n",
    "                annotation_boxes[:, 2] = _annotation_boxes[:, 0] + _annotation_boxes[:, 2] / 2\n",
    "                annotation_boxes[:, 3] = _annotation_boxes[:, 1] + _annotation_boxes[:, 3] / 2\n",
    "                annotation_boxes *= opt.img_size\n",
    "\n",
    "                for label in range(num_classes):\n",
    "                    all_annotations[-1][label] = annotation_boxes[annotation_labels == label, :]\n",
    "\n",
    "    average_precisions = {}\n",
    "    for label in range(num_classes):\n",
    "        if labels_to_classes[label] != -1:\n",
    "            true_positives = []\n",
    "            scores = []\n",
    "            num_annotations = 0\n",
    "\n",
    "            for i in range(len(all_annotations)):\n",
    "                detections = all_detections[i][label]\n",
    "                annotations = all_annotations[i][label]\n",
    "\n",
    "                num_annotations += annotations.shape[0]\n",
    "                detected_annotations = []\n",
    "\n",
    "                for *bbox, score in detections:\n",
    "                    scores.append(score)\n",
    "\n",
    "                    if annotations.shape[0] == 0:\n",
    "                        true_positives.append(0)\n",
    "                        continue\n",
    "\n",
    "                    overlaps = bbox_iou_numpy(np.expand_dims(bbox, axis=0), annotations)\n",
    "                    assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                    max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "                    if max_overlap >= opt.iou_thres and assigned_annotation not in detected_annotations:\n",
    "                        true_positives.append(1)\n",
    "                        detected_annotations.append(assigned_annotation)\n",
    "                    else:\n",
    "                        true_positives.append(0)\n",
    "\n",
    "            # no annotations -> AP for this class is 0\n",
    "            if num_annotations == 0:\n",
    "                average_precisions[label] = 0\n",
    "                continue\n",
    "\n",
    "            true_positives = np.array(true_positives)\n",
    "            false_positives = np.ones_like(true_positives) - true_positives\n",
    "            # sort by score\n",
    "            indices = np.argsort(-np.array(scores))\n",
    "            false_positives = false_positives[indices]\n",
    "            true_positives = true_positives[indices]\n",
    "            # compute false positives and true positives\n",
    "            false_positives = np.cumsum(false_positives)\n",
    "            true_positives = np.cumsum(true_positives)\n",
    "\n",
    "            # compute recall and precision\n",
    "            recall = true_positives / num_annotations\n",
    "            precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "            # compute average precision\n",
    "            average_precision = compute_ap(recall, precision)\n",
    "            average_precisions[label] = average_precision\n",
    "\n",
    "    mAP = np.mean(list(average_precisions.values()))\n",
    "\n",
    "    if(mAP > best_mAP):\n",
    "        best_mAP = mAP\n",
    "        model.save_weights(\"%s/kitti_best.weights\" % (opt.checkpoint_dir))\n",
    "        print(\"New Best AP appear !!! %f\" % best_mAP)\n",
    "\n",
    "    batch_i += 1\n",
    "    tag = 'val' if is_val else 'subset'\n",
    "    for k , v in average_precisions.items():\n",
    "        avg_precision[tag +'_mAP_' + labels[k]].append(v) \n",
    "    avg_precision[tag + '_mAP'].append(mAP)\n",
    "    print_str = 'mAP on validation' if is_val else 'mAP on subset'\n",
    "    print(print_str)\n",
    "    for k , v in avg_precision.items():\n",
    "        print('Iteration:', iteration, k,': ', v[-1])\n",
    "        vis.plot(k, v[-1], iteration)\n",
    "\n",
    "    with open(os.path.join(opt.checkpoint_dir, opt.query_mode + '_' + tag + '_avg_p_dict.pkl'), 'wb') as f:\n",
    "            pickle.dump(avg_precision, f)\n",
    "\n",
    "    return best_mAP, avg_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "The next code snippet defines a function for re-training the mode. The code can also be used to evaluate the model accoring the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(model, dataloader, epochs, optimizer, vis, total_steps, checkpoint_dir, iteration, labels_to_classes =None, is_training=True):\n",
    "    model.train(is_training)\n",
    "    freeze_backbone = 1 if iteration == 0 or iteration==1 else 0\n",
    "    accumulated_batches = 4\n",
    "    losses_list = defaultdict(list)\n",
    "    for epoch in range(epochs if is_training else 1):\n",
    "            # train\n",
    "        # Freeze darknet53.conv.74 layers for first some epochs\n",
    "        if freeze_backbone and is_training:\n",
    "            if epoch < 60:\n",
    "                for i, (name, p) in enumerate(model.named_parameters()):\n",
    "                    if int(name.split('.')[1]) < 75:  # if layer < 75\n",
    "                        p.requires_grad = False\n",
    "            elif epoch >= 60:\n",
    "                for i, (name, p) in enumerate(model.named_parameters()):\n",
    "                    if int(name.split('.')[1]) < 75:  # if layer < 75\n",
    "                        p.requires_grad = True\n",
    "        if is_training:                \n",
    "            optimizer.zero_grad()   \n",
    "\n",
    "        for batch_i, (_, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc='training' if is_training else 'Loss_evaluation')): \n",
    "            imgs = imgs.to('cuda')\n",
    "            targets = targets.to('cuda')\n",
    "            if labels_to_classes is not None:\n",
    "                no_annotation_ind = targets.sum(-1) != 0.0\n",
    "                tensor_labels_to_class = torch.tensor(labels_to_classes).to('cuda')\n",
    "                x, y = torch.nonzero(no_annotation_ind, as_tuple=True)\n",
    "                targets[x, y, 0] = tensor_labels_to_class[targets[x, y, 0].long()].double()\n",
    "\n",
    "            if is_training:\n",
    "                loss = model(imgs, targets)\n",
    "                loss.backward()\n",
    "                if ((batch_i + 1) % accumulated_batches == 0) or (batch_i == len(dataloader) - 1):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                total_steps += 1   \n",
    "                \n",
    "                if (batch_i+1) % 1 == 0:\n",
    "                    for tag, value in model.losses.items():\n",
    "                        vis.plot('losses_' + tag, value, total_steps)\n",
    "                    vis.plot('total_loss', loss.item(), total_steps)\n",
    "                    print(\n",
    "                        \"[Epoch %d/%d, Batch %d/%d] [Losses: x %f, y %f, w %f, h %f, conf %f, cls %f, total %f, recall: %.5f, precision: %.5f]\"\n",
    "                        % (\n",
    "                            epoch,\n",
    "                            epochs,\n",
    "                            batch_i,\n",
    "                            len(dataloader),\n",
    "                            model.losses[\"x\"],\n",
    "                            model.losses[\"y\"],\n",
    "                            model.losses[\"w\"],\n",
    "                            model.losses[\"h\"],\n",
    "                            model.losses[\"conf\"],\n",
    "                            model.losses[\"cls\"],\n",
    "                            loss.item(),\n",
    "                            model.losses[\"recall\"],\n",
    "                            model.losses[\"precision\"],\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    loss = model(imgs, targets)\n",
    "                    for k , v in model.losses.items():\n",
    "                        losses_list[k].append(v)\n",
    "                    losses_list['total_loss'].append(loss.item())\n",
    "            # model.seen += imgs.size(0)\n",
    "        losses_list = None if is_training else {k: np.array(v).mean() for k , v in losses_list.items()}   \n",
    "    return total_steps, losses_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "The next code snippet use the mentioned function to running the iterations of ML-assisted data annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the parameters regarding the pre-trained model, dataset for the annotation, and training hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MargParse object at 0x000001876EEC8D48>\n"
     ]
    }
   ],
   "source": [
    "###### Argparse class\n",
    "class MargParse():\n",
    "    def __init__(self, opt):\n",
    "        for k , v in opt.items():\n",
    "            setattr(self, k, v)\n",
    "# Initialise Parameters\n",
    "opt = {}\n",
    "####### dataset & evaluation settings ############################################\n",
    "opt['model_name'] = \"yolov3-coco\" # path to current model config file\n",
    "opt['data_dir'] = \"./data/kitti_tiny/training\" # path to data config file\n",
    "opt['data_format'] = \"kitti\" # data format for loading data choose from ['kitti', 'coco', 'nuimage']\n",
    "opt['iou_thres'] = 0.5 # iou threshold required to qualify as detected\n",
    "opt['conf_thres'] = 0.8 # object confidence threshold\n",
    "opt['nms_thres'] = 0.4 # iou thresshold for non-maximum suppression\n",
    "####### training settings ########################################\n",
    "opt['epochs'] = 3 # Number of epochs\n",
    "opt['batch_size'] = 8 # size of each image batch\n",
    "opt['subset_size'] = 25 # size of the subset\n",
    "opt['performance_thres'] = 0.5 # performance threshold for continuing the model refinement\n",
    "opt['img_size'] = 416 # size of each image dimension\n",
    "opt['checkpoint_dir'] = 'checkpoints' # directory where model checkpoints are saved\n",
    "opt['query_mode'] = 'random' # mode of active learning subset selection\n",
    "opt['exp_name'] = 'random'  # name of this experiment\n",
    "####### general settings\n",
    "opt['use_cuda'] = True ## use cuda for processings\n",
    "opt['visualise_detection'] = False ## visualise detection for debugging\n",
    "opt['n_cpu'] = 4 # number of cpu threads to use during batch generation\n",
    "\n",
    "opt = MargParse(opt)\n",
    "# parse arguments\n",
    "print(opt)\n",
    "img_size = opt.img_size\n",
    "## Setting the random seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the random seed and instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hamed\\anaconda3\\envs\\mltoolkit\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "cfg = f'config/{opt.model_name}.cfg'\n",
    "weights_path = f'checkpoints/{opt.model_name}.weights'\n",
    "###########################  creating class-to-label and lable-to-class maps\n",
    "model = Darknet(cfg, img_size=img_size)\n",
    "classes = model.hyperparams['classes'].split(',')\n",
    "model.apply(weights_init_normal)\n",
    "model.load_weights(weights_path)\n",
    "# resize_tuple = (1224, 370)\n",
    "resize_tuple = None\n",
    "########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,  we list the classes of the pre-trained model. The user must define its own labels and map each label to a class shown in the classes-to-labels list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes of the pretrained model:\n",
      " ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic_light', 'fire hydrant', 'stop_sign', 'parking_meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis_racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "classes_dict = {c:i for i, c in enumerate(classes)}\n",
    "print('Classes of the pretrained model:\\n',classes)\n",
    "###### The user should define its own labels and the labels-to-class map. If doesn't match any class put -1 in the list.\n",
    "labels = ['Car','Truck', 'Pedestrian', 'static_object']\n",
    "labels_to_classes = ['car', 'truck', 'person', -1]\n",
    "#######################################################################\n",
    "classes_to_labels = -1 * np.ones(len(classes_dict))\n",
    "\n",
    "for i, l in enumerate(labels_to_classes):\n",
    "    if l != -1:\n",
    "        labels_to_classes[i] = classes_dict[l]\n",
    "        classes_to_labels[classes_dict[l]] = i\n",
    "\n",
    "num_labels = len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is ready\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP_evaluation: 100%|██████████| 2/2 [00:05<00:00,  2.82s/it]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best AP appear !!! 0.429522\n",
      "mAP on validation\n",
      "Iteration: 0 val_mAP_Car :  0.4804861111111112\n",
      "Iteration: 0 val_mAP_Truck :  0.4444444444444444\n",
      "Iteration: 0 val_mAP_Pedestrian :  0.36363636363636365\n",
      "Iteration: 0 val_mAP :  0.42952230639730643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP_evaluation: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best AP appear !!! 0.473806\n",
      "mAP on subset\n",
      "Iteration: 0 subset_mAP_Car :  0.5785616963869359\n",
      "Iteration: 0 subset_mAP_Truck :  0.5928571428571427\n",
      "Iteration: 0 subset_mAP_Pedestrian :  0.25\n",
      "Iteration: 0 subset_mAP :  0.47380627974802625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 0/4] [Losses: x 0.213886, y 0.099815, w 5.332868, h 2.312359, conf 18.083305, cls 1.375719, total 27.417952, recall: 0.26667, precision: 0.39444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 1/4] [Losses: x 0.252892, y 0.086150, w 5.951696, h 2.691932, conf 20.822782, cls 1.376088, total 31.181541, recall: 0.30108, precision: 0.43684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 2/4] [Losses: x 0.224635, y 0.155890, w 6.150463, h 3.010690, conf 18.333493, cls 1.376956, total 29.252127, recall: 0.22807, precision: 0.23864]\n",
      "[Epoch 0/3, Batch 3/4] [Losses: x 0.112565, y 0.137960, w 5.379817, h 3.041387, conf 18.146183, cls 10.705959, total 37.523869, recall: 0.40000, precision: 0.47619]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 4/4 [00:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 0/4] [Losses: x 0.216084, y 0.112215, w 0.992746, h 1.702456, conf 0.893667, cls 1.372383, total 5.289552, recall: 0.66667, precision: 0.12229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 1/4] [Losses: x 0.170177, y 0.091810, w 0.877093, h 1.749662, conf 0.953945, cls 1.358816, total 5.201501, recall: 0.65714, precision: 0.12943]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 2/4] [Losses: x 0.242648, y 0.068673, w 0.932186, h 1.348275, conf 0.642783, cls 1.397177, total 4.631743, recall: 0.63333, precision: 0.11547]\n",
      "[Epoch 1/3, Batch 3/4] [Losses: x 0.221220, y 0.080360, w 0.274331, h 1.027227, conf 1.118091, cls 10.941295, total 13.662525, recall: 0.70370, precision: 0.20667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 0/4] [Losses: x 0.198397, y 0.088250, w 8.994543, h 12.400980, conf 0.902146, cls 1.315388, total 23.899706, recall: 0.53659, precision: 0.03627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 1/4] [Losses: x 0.216735, y 0.087507, w 9.049634, h 10.557042, conf 1.073534, cls 1.299259, total 22.283710, recall: 0.55556, precision: 0.01597]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 2/4] [Losses: x 0.266999, y 0.105179, w 9.679086, h 12.457331, conf 0.834132, cls 1.301159, total 24.643887, recall: 0.49630, precision: 0.03279]\n",
      "[Epoch 2/3, Batch 3/4] [Losses: x 0.149421, y 0.110406, w 9.338990, h 12.038698, conf 0.973941, cls 10.339824, total 32.951283, recall: 0.46667, precision: 0.02626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 4/4 [00:03<00:00,  1.02it/s]\n",
      "mAP_evaluation: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it] 21.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP on validation\n",
      "Iteration: 1 val_mAP_Car :  0.020066781134745942\n",
      "Iteration: 1 val_mAP_Truck :  0.0\n",
      "Iteration: 1 val_mAP_Pedestrian :  0.30303030303030304\n",
      "Iteration: 1 val_mAP :  0.10769902805501634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP_evaluation: 100%|██████████| 4/4 [00:09<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP on subset\n",
      "Iteration: 1 subset_mAP_Car :  0.017678033862670497\n",
      "Iteration: 1 subset_mAP_Truck :  0.0\n",
      "Iteration: 1 subset_mAP_Pedestrian :  0.09564777327935223\n",
      "Iteration: 1 subset_mAP :  0.03777526904734091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 0/7] [Losses: x 0.251542, y 0.087521, w 1.233335, h 0.742251, conf 0.738591, cls 1.353442, total 4.406682, recall: 0.60000, precision: 0.02279]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 1/7] [Losses: x 0.266293, y 0.097094, w 1.235161, h 0.474597, conf 0.653649, cls 1.306750, total 4.033544, recall: 0.75000, precision: 0.03102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 2/7] [Losses: x 0.252858, y 0.100730, w 0.911937, h 0.890914, conf 0.804977, cls 1.331387, total 4.292803, recall: 0.60256, precision: 0.01880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 3/7] [Losses: x 0.244066, y 0.116481, w 1.062871, h 0.693380, conf 0.685960, cls 1.319428, total 4.122186, recall: 0.69697, precision: 0.02906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 4/7] [Losses: x 0.203612, y 0.145949, w 1.799565, h 2.321453, conf 0.866822, cls 1.356935, total 6.694335, recall: 0.43333, precision: 0.00757]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 5/7] [Losses: x 0.206619, y 0.102362, w 1.963921, h 1.931263, conf 0.667683, cls 1.318665, total 6.190511, recall: 0.53086, precision: 0.01130]\n",
      "[Epoch 0/3, Batch 6/7] [Losses: x 0.161115, y 0.128571, w 2.280692, h 2.456379, conf 0.766230, cls 5.304130, total 11.097119, recall: 0.66667, precision: 0.00655]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 7/7 [00:09<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 0/7] [Losses: x 0.167877, y 0.087706, w 1.146786, h 1.826270, conf 0.620702, cls 1.295142, total 5.144484, recall: 0.60000, precision: 0.02252]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 1/7] [Losses: x 0.221629, y 0.100538, w 1.639547, h 1.915967, conf 0.601553, cls 1.319939, total 5.799173, recall: 0.60317, precision: 0.02331]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 2/7] [Losses: x 0.203060, y 0.097439, w 1.939681, h 2.481500, conf 0.625762, cls 1.329924, total 6.677365, recall: 0.46667, precision: 0.00942]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 3/7] [Losses: x 0.192088, y 0.111622, w 2.050146, h 2.339673, conf 0.628411, cls 1.304491, total 6.626431, recall: 0.52222, precision: 0.01429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 4/7] [Losses: x 0.174728, y 0.152425, w 1.942549, h 2.470106, conf 0.566234, cls 1.356633, total 6.662675, recall: 0.51111, precision: 0.00732]\n",
      "[Epoch 1/3, Batch 5/7] [Losses: x 0.193348, y 0.107483, w 1.681719, h 0.952852, conf 0.599990, cls 1.413838, total 4.949229, recall: 0.50000, precision: 0.00671]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 6/7] [Losses: x 0.157235, y 0.163720, w 0.492739, h 0.313991, conf 0.594899, cls 5.437663, total 7.160246, recall: 0.66667, precision: 0.01152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 0/7] [Losses: x 0.140944, y 0.108797, w 1.145240, h 1.801347, conf 0.473326, cls 1.293779, total 4.963431, recall: 0.68056, precision: 0.02195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 1/7] [Losses: x 0.225392, y 0.129332, w 1.014208, h 1.180577, conf 0.498544, cls 1.308389, total 4.356441, recall: 0.64583, precision: 0.04583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 2/7] [Losses: x 0.234929, y 0.116277, w 1.100287, h 1.599968, conf 0.491621, cls 1.324650, total 4.867731, recall: 0.57333, precision: 0.01866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 3/7] [Losses: x 0.190304, y 0.093081, w 1.279493, h 0.970975, conf 0.499528, cls 1.351460, total 4.384840, recall: 0.61728, precision: 0.02158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 4/7] [Losses: x 0.134906, y 0.141532, w 0.982407, h 1.353345, conf 0.454776, cls 1.316079, total 4.383045, recall: 0.66667, precision: 0.01665]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 5/7] [Losses: x 0.224885, y 0.099081, w 0.851179, h 0.811205, conf 0.399696, cls 1.359652, total 3.745697, recall: 0.60714, precision: 0.02403]\n",
      "[Epoch 2/3, Batch 6/7] [Losses: x 0.273313, y 0.027740, w 0.294893, h 0.037206, conf 0.504498, cls 5.105692, total 6.243343, recall: 1.00000, precision: 0.02211]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "mAP_evaluation: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it] 32.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP on validation\n",
      "Iteration: 2 val_mAP_Car :  0.29752870275193893\n",
      "Iteration: 2 val_mAP_Truck :  0.0\n",
      "Iteration: 2 val_mAP_Pedestrian :  0.4568181818181818\n",
      "Iteration: 2 val_mAP :  0.25144896152337354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP_evaluation: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP on subset\n",
      "Iteration: 2 subset_mAP_Car :  0.6275967583281106\n",
      "Iteration: 2 subset_mAP_Truck :  0.0\n",
      "Iteration: 2 subset_mAP_Pedestrian :  0.6666666666666666\n",
      "Iteration: 2 subset_mAP :  0.4314211416649257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 0/8] [Losses: x 0.144126, y 0.125506, w 0.495413, h 0.778619, conf 0.375145, cls 1.316189, total 3.234998, recall: 0.81481, precision: 0.04808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 1/8] [Losses: x 0.166302, y 0.123787, w 0.745127, h 1.006504, conf 0.420249, cls 1.377044, total 3.839013, recall: 0.60870, precision: 0.02565]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 2/8] [Losses: x 0.210604, y 0.083907, w 0.428952, h 0.573253, conf 0.353687, cls 1.312813, total 2.963216, recall: 0.76543, precision: 0.04235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 3/8] [Losses: x 0.241386, y 0.104334, w 0.732711, h 0.597403, conf 0.376146, cls 1.309541, total 3.361521, recall: 0.80392, precision: 0.05995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 4/8] [Losses: x 0.186461, y 0.091185, w 0.637446, h 0.650490, conf 0.348792, cls 1.336110, total 3.250483, recall: 0.74074, precision: 0.03024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 5/8] [Losses: x 0.189249, y 0.071275, w 0.694201, h 0.623760, conf 0.369457, cls 1.306233, total 3.254175, recall: 0.83333, precision: 0.04442]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3, Batch 6/8] [Losses: x 0.221516, y 0.099868, w 0.483521, h 0.380591, conf 0.341520, cls 1.292165, total 2.819181, recall: 0.85556, precision: 0.06117]\n",
      "[Epoch 0/3, Batch 7/8] [Losses: x 0.150293, y 0.048694, w 0.522420, h 0.656290, conf 0.392670, cls 2.630042, total 4.400410, recall: 0.80000, precision: 0.07643]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 8/8 [00:09<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 0/8] [Losses: x 0.168846, y 0.081569, w 0.277309, h 0.385341, conf 0.387788, cls 1.340274, total 2.641127, recall: 0.73611, precision: 0.04190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 1/8] [Losses: x 0.199104, y 0.076670, w 0.458319, h 0.382543, conf 0.310090, cls 1.301562, total 2.728288, recall: 0.79310, precision: 0.05564]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 2/8] [Losses: x 0.157177, y 0.086795, w 0.482217, h 0.380354, conf 0.318600, cls 1.319536, total 2.744679, recall: 0.81159, precision: 0.04707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 3/8] [Losses: x 0.193747, y 0.041522, w 0.569772, h 0.385189, conf 0.355332, cls 1.335017, total 2.880579, recall: 0.77273, precision: 0.04669]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 4/8] [Losses: x 0.165885, y 0.061159, w 0.513723, h 0.415704, conf 0.251728, cls 1.299265, total 2.707463, recall: 0.88889, precision: 0.06309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 5/8] [Losses: x 0.144488, y 0.065823, w 0.915573, h 0.677056, conf 0.350280, cls 1.388649, total 3.541868, recall: 0.54762, precision: 0.01654]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3, Batch 6/8] [Losses: x 0.199086, y 0.087420, w 0.439580, h 0.299684, conf 0.346093, cls 1.294404, total 2.666267, recall: 0.88667, precision: 0.11233]\n",
      "[Epoch 1/3, Batch 7/8] [Losses: x 0.215999, y 0.061627, w 1.030073, h 0.292084, conf 0.231578, cls 2.595105, total 4.426465, recall: 0.75556, precision: 0.06445]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 8/8 [00:09<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 0/8] [Losses: x 0.200021, y 0.068315, w 0.421213, h 0.351939, conf 0.322740, cls 1.298150, total 2.662378, recall: 0.88596, precision: 0.09439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 1/8] [Losses: x 0.159162, y 0.060847, w 0.727462, h 0.494973, conf 0.269082, cls 1.317893, total 3.029419, recall: 0.84444, precision: 0.03932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 2/8] [Losses: x 0.177791, y 0.087217, w 0.399082, h 0.303450, conf 0.287584, cls 1.311349, total 2.566473, recall: 0.81481, precision: 0.08127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 3/8] [Losses: x 0.179924, y 0.073809, w 0.498677, h 0.371128, conf 0.285906, cls 1.341311, total 2.750754, recall: 0.69048, precision: 0.05090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 4/8] [Losses: x 0.193364, y 0.090550, w 0.503781, h 0.579965, conf 0.304267, cls 1.322467, total 2.994393, recall: 0.71930, precision: 0.03868]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 5/8] [Losses: x 0.213649, y 0.135141, w 0.187920, h 0.298896, conf 0.277077, cls 1.304579, total 2.417262, recall: 0.73913, precision: 0.04609]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/3, Batch 6/8] [Losses: x 0.233165, y 0.094271, w 0.351770, h 0.403305, conf 0.271071, cls 1.298930, total 2.652513, recall: 0.78161, precision: 0.06445]\n",
      "[Epoch 2/3, Batch 7/8] [Losses: x 0.128279, y 0.099183, w 0.360044, h 0.475192, conf 0.331503, cls 2.575007, total 3.969209, recall: 0.84615, precision: 0.06266]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 8/8 [00:09<00:00,  1.17s/it]\n",
      "model refining iterations: 100%|██████████| 3/3 [01:42<00:00, 34.19s/it]\n",
      "mAP_evaluation: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP on validation\n",
      "Iteration: 2 val_mAP_Car :  0.22690266529609884\n",
      "Iteration: 2 val_mAP_Truck :  0.0\n",
      "Iteration: 2 val_mAP_Pedestrian :  0.5393939393939394\n",
      "Iteration: 2 val_mAP :  0.25543220156334606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "############################ Instantiating visualiser\n",
    "opt.checkpoint_dir = opt.checkpoint_dir + '/' + opt.exp_name\n",
    "vis = Visualizer(opt.checkpoint_dir)\n",
    "os.makedirs(opt.checkpoint_dir, exist_ok=True)\n",
    "############################ Instantiating and loading the model\n",
    "cuda = torch.cuda.is_available() and opt.use_cuda\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "    classes_to_labels = torch.from_numpy(classes_to_labels).to('cuda')\n",
    "    print(\"CUDA is ready\")\n",
    "\n",
    "unlabelled_set = Image2DAnnotationDataset(opt.data_dir, labels, labels_to_classes, opt.data_format, img_size, resize_tuple)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "val_best_mAP = 0.0\n",
    "subset_best_mAP = 0.0\n",
    "\n",
    "subset_size = opt.subset_size\n",
    "print(\"start training\")\n",
    "\n",
    "#### Start the annotation ... \n",
    "total_steps = 0\n",
    "random_ordered_indices = np.arange(len(unlabelled_set))\n",
    "random.shuffle(random_ordered_indices)\n",
    "len_val_set = int(0.2 * len(unlabelled_set))\n",
    "val_set = Subset(unlabelled_set, random_ordered_indices[ :len_val_set])\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=opt.batch_size, shuffle=False, num_workers=opt.n_cpu)\n",
    "unlabelled_set = Subset(unlabelled_set, random_ordered_indices[len_val_set:])\n",
    "\n",
    "val_avg_p_dict = defaultdict(list)\n",
    "subset_avg_p_dict = defaultdict(list)\n",
    "len_test_dataset = len(unlabelled_set)\n",
    "labelled_subset_list = []\n",
    "avg_losses_list = defaultdict(list)\n",
    "for i in tqdm.tqdm(range(int(np.ceil(len_test_dataset / subset_size))), desc='model refining iterations'):\n",
    "    ################### Subset selection ###################################\n",
    "    labelled_sub_dataset, subset_indices = subset_selection(model, unlabelled_set, subset_size, opt.query_mode, opt)\n",
    "    \n",
    "    remaining_indices = set(np.arange(len(unlabelled_set))).difference(subset_indices)\n",
    "    unlabelled_set = Subset(unlabelled_set, list(remaining_indices))\n",
    "    ################### Visualise Detection #################################\n",
    "    # np.random.randint(0, len(labelled_sub_dataset))\n",
    "    if opt.visualise_detection:\n",
    "        img_path, img, target = unlabelled_set[0]\n",
    "        visualise_annotation(model, img_path, img, target,classes_to_labels, opt, labels, img_size, resize_tuple, show_target=True)\n",
    "    # ################### Evaluation ########################################\n",
    "    labelled_sub_set_loader = torch.utils.data.DataLoader(labelled_sub_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.n_cpu)\n",
    "    ### Calculate MAP\n",
    "    val_best_mAP, val_avg_p_dict = evaluate(model, val_loader, num_labels, opt, val_best_mAP, classes_to_labels, labels_to_classes, val_avg_p_dict, labels, vis, i, is_val=True)\n",
    "\n",
    "    subset_best_mAP, subset_avg_p_dict = evaluate(model, labelled_sub_set_loader, num_labels, opt, subset_best_mAP, classes_to_labels, labels_to_classes, subset_avg_p_dict, labels, vis, i, is_val=False)\n",
    "\n",
    "    # _, losses_list = calc_loss(model, val_loader, opt.epochs, optimizer, vis, total_steps, opt.checkpoint_dir, i, labels_to_classes, is_training=False)\n",
    "    # for k , v in losses_list.items():\n",
    "    #     avg_losses_list[k].append(v)\n",
    "    # for tag, loss in avg_losses_list.items():\n",
    "    #     vis.plot('losses_' + tag, loss[-1], i)\n",
    "    \n",
    "    ###### check performance #######################################################\n",
    "    if val_best_mAP > opt.performance_thres:\n",
    "        break\n",
    "    ##################### Training #############################################\n",
    "    labelled_subset_list.append(labelled_sub_dataset)\n",
    "    train_set = ConcatDataset(labelled_subset_list)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)\n",
    "    total_steps, _ = calc_loss(model, train_loader, opt.epochs, optimizer, vis, total_steps, opt.checkpoint_dir, i, labels_to_classes)\n",
    "            \n",
    "    ################### Saving the Model ####################################\n",
    "    model.save_weights(\"%s/best.weights\" % (opt.checkpoint_dir))\n",
    "    \n",
    "### Calculate MAP afte the last training    \n",
    "_, val_avg_p_dict = evaluate(model, val_loader, num_labels, opt, val_best_mAP, classes_to_labels, labels_to_classes, val_avg_p_dict, labels, vis, i, is_val=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "82c675a00330a34e872d3ab47a866e4333677a7f7c38acb82d8488d8cd828596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
